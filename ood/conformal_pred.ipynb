{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. generate conformal sets (representations) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import models\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FeatureExtractor(torch.nn.Module):\n",
    "#     \"\"\"Get representation of intermediary layer.\n",
    "#     base_model (<-- we extract here), fc, sigmoid\n",
    "#     \"\"\"\n",
    "#     def __init__(self, model, layer='4'): # layer is 0..8\n",
    "#         super().__init__()\n",
    "#         self.model = model\n",
    "#         self.layer = layer\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         for name, module in self.model.base_model.named_children():\n",
    "#             print(name)\n",
    "#             x = module(x)\n",
    "#             if name == self.layer:\n",
    "#                 return x\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # layer names\n",
    "# for x,y in loaded_model.base_model.named_children():\n",
    "#     print(x)\n",
    "#     print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (base_model): Sequential(\n",
       "    (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os; print(os.getcwd())\n",
    "dir_in = '../'\n",
    "pos_image_path = 'combined_images_parasite'\n",
    "neg_image_path = 'combined_images_neg'\n",
    "model_path = 'model_perf_r34_b32'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    loaded_model = torch.load(dir_in + model_path + '.pt')\n",
    "else:\n",
    "    loaded_model = torch.load(dir_in + model_path + '.pt',map_location=torch.device('cpu'))\n",
    "\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76126, 744187)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load images\n",
    "pos_images = np.load(dir_in + 'data/' + pos_image_path + '.npy')\n",
    "neg_images = np.load(dir_in + 'data/' + neg_image_path + '.npy')\n",
    "\n",
    "pos_images.shape[0], neg_images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "import random\n",
    "\n",
    "def create_conformal_set(model, data, labels, num_subsets=100, subset_size=1000):\n",
    "    \"\"\"\n",
    "    Outputs combined conformal set with pos and neg images.\n",
    "    \"\"\"\n",
    "    best_f2 = -99999\n",
    "    best_set = 0\n",
    "\n",
    "    for _ in range(num_subsets):\n",
    "        subset_indices = random.sample(range(len(pos_images)), subset_size)\n",
    "        subset_indices += random.sample(range(len(pos_images), len(neg_images)), subset_size)\n",
    "        \n",
    "        subset = data[subset_indices]\n",
    "        y = labels[subset_indices]\n",
    "        outputs, features = utils.generate_predictions_and_features(model,subset,32)\n",
    "\n",
    "        threshold = 0.85\n",
    "        #0 for negative, 1 for positive, and 2 for unsure\n",
    "        pred = (outputs[:,1] >= threshold).astype(int)\n",
    "        # print(outputs.shape)\n",
    "        # print(pred.shape)\n",
    "        \n",
    "        # if labels == 1:\n",
    "        #     y = np.ones(len(pred), dtype='float64')\n",
    "        # if labels == 0:\n",
    "        #     y = np.zeros(len(pred), dtype='float64')\n",
    "\n",
    "        # Calculate F2 score\n",
    "        f2_score = fbeta_score(y, pred, beta=2)\n",
    "        print(f2_score)\n",
    "\n",
    "        if f2_score > best_f2:\n",
    "            best_f2 = f2_score\n",
    "            best_set = (subset, features, y)\n",
    "\n",
    "    return best_set, best_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8315964985410588\n",
      "0.8246346555323592\n",
      "0.8315964985410588\n",
      "0.8176495190296947\n",
      "0.8000839983200335\n",
      "0.8263772954924875\n",
      "0.7841483979763912\n",
      "0.8000839983200335\n",
      "0.8088851634534786\n",
      "0.7734573119188504\n",
      "0.8106409719312946\n",
      "0.7983193277310925\n",
      "0.8333333333333334\n",
      "0.8088851634534786\n",
      "0.7894736842105263\n",
      "0.8018471872376155\n",
      "0.8036088963491398\n",
      "0.8402662229617305\n",
      "0.8211450062682826\n",
      "0.8193979933110368\n",
      "0.8071278825995808\n",
      "0.7947855340622372\n",
      "0.7965531736023539\n",
      "0.8123953098827471\n",
      "0.7912457912457912\n",
      "0.7965531736023539\n",
      "0.8176495190296947\n",
      "0.8141481791544579\n",
      "0.8263772954924875\n",
      "0.8141481791544579\n",
      "0.8211450062682826\n",
      "0.8106409719312946\n",
      "0.7965531736023539\n",
      "0.8018471872376155\n",
      "0.8350687213660974\n",
      "0.8018471872376155\n",
      "0.8018471872376155\n",
      "0.8193979933110368\n",
      "0.8071278825995808\n",
      "0.8053691275167786\n",
      "0.7894736842105263\n",
      "0.8281184814351272\n",
      "0.8071278825995808\n",
      "0.8368026644462948\n",
      "0.8123953098827471\n",
      "0.8193979933110368\n",
      "0.8123953098827471\n",
      "0.8000839983200335\n",
      "0.8123953098827471\n",
      "0.850622406639004\n",
      "0.8141481791544579\n",
      "0.8000839983200335\n",
      "0.8036088963491398\n",
      "0.8018471872376155\n",
      "0.7752429235318969\n",
      "0.8298582151793161\n",
      "0.7841483979763912\n",
      "0.8036088963491398\n",
      "0.8158995815899582\n",
      "0.8106409719312946\n",
      "0.8437240232751455\n",
      "0.8158995815899582\n",
      "0.7930164072360119\n",
      "0.7912457912457912\n",
      "0.8018471872376155\n",
      "0.8123953098827471\n",
      "0.8281184814351272\n",
      "0.822890559732665\n",
      "0.8088851634534786\n",
      "0.8141481791544579\n",
      "0.8053691275167786\n",
      "0.7930164072360119\n",
      "0.8158995815899582\n",
      "0.8211450062682826\n",
      "0.8088851634534786\n",
      "0.8141481791544579\n",
      "0.8176495190296947\n",
      "0.8298582151793161\n",
      "0.8246346555323592\n",
      "0.8333333333333334\n",
      "0.8088851634534786\n",
      "0.7965531736023539\n",
      "0.8211450062682826\n",
      "0.8263772954924875\n",
      "0.8141481791544579\n",
      "0.8333333333333334\n",
      "0.8106409719312946\n",
      "0.8071278825995808\n",
      "0.8211450062682826\n",
      "0.8018471872376155\n",
      "0.838535164377861\n",
      "0.8123953098827471\n",
      "0.7983193277310925\n",
      "0.8333333333333334\n",
      "0.822890559732665\n",
      "0.7912457912457912\n",
      "0.8000839983200335\n",
      "0.8000839983200335\n",
      "0.8158995815899582\n",
      "0.8211450062682826\n"
     ]
    }
   ],
   "source": [
    "num_subsets = 100 # number of subsets to try\n",
    "subset_size = 500 # *2 = how many samples in conformal set\n",
    "\n",
    "data = np.concatenate([pos_images, neg_images])\n",
    "labels = np.concatenate([np.ones(len(pos_images), dtype='float64'), np.zeros(len(neg_images), dtype='float64')])\n",
    "best_set, f2_score = create_conformal_set(loaded_model, data, labels, num_subsets, subset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset, h_train, y = best_set\n",
    "t_pos = subset[y == 1]\n",
    "t_neg = subset[y == 0]\n",
    "h_pos = h_train[y == 1]\n",
    "h_neg = h_train[y == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save images for conformal set\n",
    "np.save('conformal_set_pos.npy', t_pos)\n",
    "np.save('conformal_set_neg.npy', t_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. noncoformal prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.05 # 95% confidence new test example is not non-conformant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repr(samples, batch_size=1):\n",
    "    if len(samples.shape) == 3: # single image\n",
    "        samples = np.expand_dims(samples, axis=0)\n",
    "    _, h_sample = utils.generate_predictions_and_features(loaded_model,samples,batch_size)\n",
    "    return h_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.nature.com/articles/s41746-021-00504-6\n",
    "\n",
    "def nonconformity_measure(hs):\n",
    "    \"\"\"\n",
    "    Output: vector of nonconformity scores for each repr\n",
    "    greater values (i.e. less negative) mean greater non-conformity/ood\n",
    "    \"\"\"\n",
    "    similarities = cosine_similarity(hs) # nxn matrix\n",
    "    scores = -np.sum(similarities - np.eye(similarities.shape[0]), axis=1)  # subtract cosine similarity of sample with itself\n",
    "    # print(scores)\n",
    "    return scores\n",
    "\n",
    "def single_p_value(h_train, h_sample):\n",
    "    \"\"\"Calculates how different sample is compared to training distribution\n",
    "    Output: p_value\n",
    "    If p<epsilon, then it is o.o.d\n",
    "    \"\"\"\n",
    "    hs = np.concatenate([h_train, h_sample], axis=0)\n",
    "    scores = nonconformity_measure(hs)\n",
    "    sample_score = scores[-1]\n",
    "    p_value = np.mean(scores[:-1] >= sample_score)\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.346 0.0\n",
      "True False\n"
     ]
    }
   ],
   "source": [
    "# sample to test\n",
    "h_sample = get_repr(pos_images[10])\n",
    "\n",
    "pos_p_value = single_p_value(h_pos, h_sample)\n",
    "neg_p_value = single_p_value(h_neg, h_sample)\n",
    "\n",
    "# makes sense since the pos sample is in dist for pos!\n",
    "print(pos_p_value, neg_p_value)\n",
    "print(pos_p_value>epsilon, neg_p_value>epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if test slides are o.o.d using conformal pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71786, 4, 31, 31)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_path = 'PAT-109-2_2023-06-03_23-38-20.797186'\n",
    "test_set = np.load(dir_in + 'data/' + test_image_path + '.npy')\n",
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conformal_test(h_pos, h_neg, test_set, num_samples):\n",
    "    \"\"\"\n",
    "    Classified as o.o.d if in neither of pos or neg distibutions\n",
    "    output: array of o.o.d images\n",
    "    \"\"\"\n",
    "\n",
    "    h_test_set = get_repr(test_set, 32)\n",
    "    ood_set = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        image = test_set[i]\n",
    "        h_sample = np.expand_dims(h_test_set[i], axis=0)\n",
    "        pos_p_value = single_p_value(h_pos, h_sample)\n",
    "        neg_p_value = single_p_value(h_neg, h_sample)\n",
    "\n",
    "        if pos_p_value < epsilon and neg_p_value < epsilon:\n",
    "            ood_set.append(image)\n",
    "\n",
    "    return ood_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_set = conformal_test(h_pos, h_neg, test_set, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save('ood_images.npy', ood_set)\n",
    "len(ood_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: can try to precompute pos and neg calibration scores (still need to include H_M+1, the test sample, in the calib predictions...)\n",
    "\n",
    "# def conformal_test(h_pos, h_neg, test_set):\n",
    "#     \"\"\"\n",
    "#     Classified as o.o.d if in neither of pos or neg distibutions\n",
    "#     output: array of o.o.d images\n",
    "#     \"\"\"\n",
    "\n",
    "#     pos_calib_scores = nonconformity_measure(h_pos)\n",
    "#     neg_calib_scores = nonconformity_measure(h_neg)\n",
    "#     ood_set = []\n",
    "\n",
    "#     for image in test_set:\n",
    "#         h_sample = get_repr(image)\n",
    "\n",
    "#         # p(h|pos)\n",
    "#         similarity = cosine_similarity(h_pos, h_sample)   # (2000) vector comparing sample to conformal set\n",
    "#         sample_score = -np.sum(similarity, axis=1)\n",
    "#         print(sample_score)\n",
    "#         p_value = np.mean(pos_calib_scores >= sample_score)\n",
    "#         print(p_value)\n",
    "#         if p_value >= epsilon:\n",
    "#             break\n",
    "        \n",
    "#         # p(h|neg)\n",
    "#         similarity = cosine_similarity(h_neg, h_sample)   # (2000) vector comparing sample to conformal set\n",
    "#         sample_score = -np.sum(similarity, axis=1)\n",
    "#         p_value = np.mean(neg_calib_scores >= sample_score)\n",
    "#         print(p_value)\n",
    "        \n",
    "#         if p_value < epsilon:\n",
    "#             ood_set.append(image)\n",
    "    \n",
    "#     return ood_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check: do this for the positive samples, flagged ood should be very low\n",
    "ood_test_set = conformal_test(h_pos, h_neg, pos_images, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ood_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
