{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use activelab: https://github.com/cleanlab/examples/blob/master/active_learning_single_annotator/active_learning_single_annotator.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/squid/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cleanlab.multiannotator import get_label_quality_scores, get_active_learning_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.py\n",
    "\n",
    "models_dict = {'resnet18': torchvision.models.resnet18,\n",
    "               'resnet34': torchvision.models.resnet34,\n",
    "               'resnet50': torchvision.models.resnet50,\n",
    "               'resnet101': torchvision.models.resnet101,\n",
    "               'resnet152': torchvision.models.resnet152}\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, model='resnet18',n_channels=4,n_filters=64,n_classes=1,kernel_size=3,stride=1,padding=1):\n",
    "        super().__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.base_model = models_dict[model](pretrained=True)\n",
    "        self._feature_vector_dimension = self.base_model.fc.in_features\n",
    "        self.base_model.conv1 = nn.Conv2d(n_channels, n_filters, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
    "        self.base_model = nn.Sequential(*list(self.base_model.children())[:-1]) # Remove the final fully connected layer\n",
    "        self.fc = nn.Linear(self._feature_vector_dimension, n_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        features = x.view(x.size(0), -1)\n",
    "        return self.fc(features)\n",
    "\n",
    "    def extract_features(self,x):\n",
    "        x = self.base_model(x)\n",
    "        return x.view(x.size(0), -1)\n",
    "    \n",
    "    def extract_early_features(self, x):  # try earlier layer\n",
    "        x = self.base_model.conv1(x)\n",
    "        x = self.base_model.bn1(x)\n",
    "        x = self.base_model.relu(x)\n",
    "        x = self.base_model.maxpool(x)\n",
    "        x = self.base_model.layer1(x)\n",
    "\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "    def get_predictions(self,x):\n",
    "        x = self.base_model(x)\n",
    "        features = x.view(x.size(0), -1)\n",
    "        output = self.fc(features)\n",
    "        if self.n_classes == 1:\n",
    "            return torch.sigmoid(output)\n",
    "        else:\n",
    "            return torch.softmax(output,dim=1)\n",
    "\n",
    "    def get_predictions_and_features(self,x):\n",
    "        x = self.base_model(x)\n",
    "        features = x.view(x.size(0), -1)\n",
    "        output = self.fc(features)\n",
    "        if self.n_classes == 1:\n",
    "            return torch.sigmoid(output), features\n",
    "        else:\n",
    "            return torch.softmax(output,dim=1), features\n",
    "\n",
    "    def get_features(self,x):\n",
    "        x = self.base_model(x)\n",
    "        features = x.view(x.size(0), -1)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.py\n",
    "\n",
    "def generate_predictions_and_features(model,images,batch_size, verbose=True):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    if images.dtype == np.uint8:\n",
    "        images = images.astype(np.float32)/255.0 # convert to 0-1 if uint8 input\n",
    "\n",
    "    # build dataset\n",
    "    dataset = TensorDataset(\n",
    "        torch.from_numpy(images), \n",
    "        torch.from_numpy(np.ones(images.shape[0]))\n",
    "        )\n",
    "\n",
    "    # dataloader\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # run inference \n",
    "    all_features = []\n",
    "    all_predictions = []\n",
    "    t0 = time.time()\n",
    "\n",
    "    for k, (images, labels) in enumerate(dataloader):\n",
    "\n",
    "        images = images.float().to(device)\n",
    "\n",
    "        predictions, features = model.get_predictions_and_features(images)\n",
    "        predictions = predictions.detach().cpu().numpy()\n",
    "        features = features.detach().cpu().numpy().squeeze()\n",
    "\n",
    "        all_predictions.append(predictions)\n",
    "        all_features.append(features)\n",
    "\n",
    "    predictions = np.vstack(all_predictions)\n",
    "    features = np.vstack(all_features)\n",
    "\n",
    "    if verbose:\n",
    "        print('running inference on ' + str(predictions.shape[0]) + ' images took ' + str(time.time()-t0) + ' s')\n",
    "\n",
    "    return predictions, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '../../npy_v2/'\n",
    "\n",
    "trained_on = ['PAT-070-3_2023-01-22_15-24-28.812821.npy',\n",
    "                'PAT-071-3_2023-01-22_15-47-3.096602.npy',\n",
    "                'PAT-072-1_2023-01-22_17-17-58.363496.npy',\n",
    "                'PAT-073-1_2023-01-22_16-32-5.192404.npy',\n",
    "                'PAT-074-1_2023-01-22_16-55-50.887780.npy',\n",
    "                'PBC-404-1_2023-01-22_19-09-9.267139.npy',\n",
    "                'PBC-502-1_2023-01-22_17-49-38.429975.npy',\n",
    "                'PBC-800-1_2023-01-22_21-30-44.794123.npy',\n",
    "                'PBC-801-1_2023-01-22_22-06-18.047215.npy',\n",
    "                'PBC-1023-1_2023-01-22_19-59-54.633046.npy']\n",
    "\n",
    "# exclude above, everything else in npy_v2 should be loaded into images_unlabelled\n",
    "files_unlabelled = [f for f in os.listdir(dir_path) if f.endswith('.npy') and f not in trained_on and not f.startswith('SBC')]\n",
    "# TODO: fold in known SBC negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_unlabelled = []\n",
    "for f in files_unlabelled[:10]: # TODO: do it in batches, 41 slides total\n",
    "    images_unlabelled.append(np.load(dir_path + f))\n",
    "\n",
    "images_unlabelled = np.vstack(images_unlabelled)\n",
    "images_unlabelled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model on labeled data and get predicted class probabilites for unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/squid/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/squid/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ResNet(model='resnet34', n_channels=4, n_filters=64, n_classes=3, kernel_size=3, stride=1, padding=1)\n",
    "model.load_state_dict(torch.load('../model_resnet34_1704164366.7755363.pt'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_query(model, images, batch_size):\n",
    "    \"\"\"\n",
    "    Selects a subset of the o.o.d. data to interactively query user to obtain labels, based on active learning.\n",
    "    \"\"\"\n",
    "    # generate predictions and features\n",
    "    pred_probs_unlabeled, features = generate_predictions_and_features(model,images,batch_size)\n",
    "    pred_probs_unlabeled = pred_probs_unlabeled.squeeze()\n",
    "\n",
    "    # compute active learning scores\n",
    "    _, active_learning_scores_unlabeled = get_active_learning_scores(\n",
    "        pred_probs_unlabeled=pred_probs_unlabeled\n",
    "        # df_labeled['label'].to_numpy(), pred_probs_unlabeled=pred_probs_unlabeled  # TODO: in the future can also choose relabeling from labeled dataset (may need ood preds)\n",
    "    )\n",
    "\n",
    "    # active_learning_scores_unlabeled[:5]\n",
    "\n",
    "    return np.argsort(active_learning_scores_unlabeled)[:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running inference on 1565289 images took 151.5050084590912 s\n"
     ]
    }
   ],
   "source": [
    "next_to_label = active_query(model, images_unlabelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 799615, 1088715,  197927,  177382,  320682,    6950,  759281,\n",
       "       1267554,  336530,  789011, 1244383, 1220176, 1273893,  760205,\n",
       "        830740, 1235760,  208420, 1351656,  494312,    2584, 1266352,\n",
       "       1284274, 1289756, 1287595, 1412573,  135135, 1248574,  528091,\n",
       "       1279330, 1086184,  376974, 1247145])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_to_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- show images to label, get user labels\n",
    "- update model\n",
    "- remove from unlabeled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(model, images, labels, num_epochs=10, learning_rate=0.1):   # TODO: simple update with higher LR, can weight based on scores/how off\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    if images.dtype == np.uint8:\n",
    "        images = images.astype(np.float32)/255.0 # convert to 0-1 if uint8 input\n",
    "\n",
    "    dataset = TensorDataset(\n",
    "        torch.from_numpy(images), \n",
    "        torch.from_numpy(labels)\n",
    "    )\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in dataloader: \n",
    "\n",
    "            inputs = inputs.float().to(device)\n",
    "            labels = labels.long().to(device)\n",
    "\n",
    "            optimizer.zero_grad() \n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running inference on 32 images took 0.23706650733947754 s\n",
      "(32, 4, 31, 31) (32, 3) (32,)\n"
     ]
    }
   ],
   "source": [
    "# simple test run\n",
    "# test = active_query(data)\n",
    "# new_model = finetune(model, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "active learning rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rounds = 10\n",
    "\n",
    "for _ in range(num_rounds):\n",
    "    # get next batch to label\n",
    "    next_to_label = active_query(model, images_unlabelled)\n",
    "    images = images_unlabelled[next_to_label]\n",
    "\n",
    "    # get labels from user\n",
    "    preds, _ = generate_predictions_and_features(model, images, 32) # TODO: already got this from active_query, can just pass in\n",
    "    labels = np.random.choice(2, len(images)) # TODO: get labels from user\n",
    "\n",
    "    # update model\n",
    "    model = update(model, images, labels, 10, 0.1)\n",
    "\n",
    "    # remove from unlabelled\n",
    "    images_unlabelled = np.delete(images_unlabelled, next_to_label, axis=0)\n",
    "\n",
    "    # TODO: evaluate on hold-out set, or stop when user no longer needs to correct\n",
    "\n",
    "np.save(model, 'model_active_learning.npy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
